{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Clonar repositório crawl4ai"
      ],
      "metadata": {
        "id": "qOPiZRxmuI9F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhAtXUF2cTbD"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/unclecode/crawl4ai.git --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Salva o histórico de merges das branches"
      ],
      "metadata": {
        "id": "LIo1qceQwvtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/crawl4ai\n",
        "!git log --graph --oneline --all --decorate --merges > /content/historico_merges.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsT6zcP6wgKp",
        "outputId": "2fcaffe4-56a4-486c-ac9b-352aabaa93c1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/crawl4ai\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lê os principais arquivos com informações relacionadas às releases e as branches"
      ],
      "metadata": {
        "id": "RBsgSI3Ew09f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "changelog = \"\"\n",
        "releases = \"\"\n",
        "merges = \"\"\n",
        "with open(\"/content/crawl4ai/CHANGELOG.md\", \"r\") as f:\n",
        "  changelog = f.read()\n",
        "with open(\"/content/crawl4ai/.github/workflows/release.yml\", \"r\") as f:\n",
        "  releases = f.read()\n",
        "with open(\"/content/historico_merges.txt\", \"r\") as f:\n",
        "  merges = f.read()"
      ],
      "metadata": {
        "id": "xECqauxQwg35"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Criação do prompt"
      ],
      "metadata": {
        "id": "eHBb-nEYzA-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_msg = f\"\"\"Você é um Especialista em Engenharia de Software com foco em Gerenciamento de Configuração. Sua tarefa é analisar o repositório \"Crawl4AI\" para identificar sua Estratégia de Release e seu Fluxo de Trabalho (Branching Model).\n",
        "\n",
        "PRINCIPAIS ESTRATÉGIAS DE WORKFLOW PARA PROCURAR:\n",
        "- Gitflow: Presença de branches persistentes 'main' E 'develop'. Merges de features vão para 'develop'. Existem branches de 'release/v*'.\n",
        "- GitHub Flow: Apenas a branch 'main' é persistente. Features branches são curtas e mergeadas direto na 'main'.\n",
        "- Trunk-based: Commits frequentes e diretos na 'main' (ou via PRs curtíssimos). O histórico é quase uma linha única e reta.\n",
        "\n",
        "PRINCIPAIS ESTRATÉGIAS DE RELEASE PARA PROCURAR:\n",
        "- Rapid Release: Alta frequência de versões (tags v* constantes) baseadas em novas funcionalidades prontas.\n",
        "- Release Train: Versões em datas fixas e previsíveis.\n",
        "- LTS + Current: Coexistência de versões estáveis de longo suporte com versões de ponta.\n",
        "\n",
        "VOCÊ RECEBERÁ DADOS DOS SEGUINTES ARQUIVOS:\n",
        "- CHANGELOG.md: Registro histórico de versões e datas.\n",
        "- release.yml: Configuração de automação do GitHub Actions.\n",
        "- Histórico de Merges: O log visual (graph) da árvore de commits.\n",
        "\n",
        "METODOLOGIA DE ANÁLISE:\n",
        "1. Examine o 'release.yml': Tente identificar o que dispara o deploy.\n",
        "2. Examine o 'CHANGELOG.md': Tente identificar o intervalo médio entre versões.\n",
        "3. Examine o 'Histórico de Merges': Procure pela existência da branch 'develop' e branches com prefixo 'release/v*', 'feature/*' ou 'fix/* e verificar a persistência dessas branches'.\n",
        "\n",
        "CONCLUSÃO:\n",
        "Apresente sua conclusão baseada na predominância das evidências. Se houver elementos de mais de um modelo (ex: um fluxo Gitflow simplificado com ritmo de Rapid Release), descreva essa governança híbrida.\"\"\"\n",
        "user_msg = f\"\"\"\n",
        "Aqui estão os arquivos a serem analisados:\n",
        "CHANGELOG.md:\n",
        "{\"\\n\".join(changelog.splitlines()[-262:])}\n",
        "\n",
        "release.yml:\n",
        "{releases}\n",
        "\n",
        "Histórico de Merges:\n",
        "{merges}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "uqRWQKZJzBXH"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rodar o modelo usando Inference Provider do Hugging Face"
      ],
      "metadata": {
        "id": "vRnJRcdlryth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ['HF_TOKEN'] = userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "id": "Lt_1YEdHjuZz"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://router.huggingface.co/v1\",\n",
        "    api_key=os.environ[\"HF_TOKEN\"],\n",
        ")\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": system_msg\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": user_msg\n",
        "        }\n",
        "    ],\n",
        "    max_tokens=1500,\n",
        "    temperature=0.2,\n",
        "    top_p=0.9\n",
        ")\n",
        "\n",
        "with open(\"/content/resposta-llama-3_2-8B-Instruct.md\", \"w\") as f:\n",
        "  f.write(completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "SJ0SRCpWnDNT"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}